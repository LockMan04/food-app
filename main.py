from flask import Flask, request, jsonify, Response
from flask_cors import CORS
from ultralytics import YOLO
import tempfile
import os
import json
import traceback
from openai import OpenAI
import uuid
from datetime import datetime, timedelta
import threading
import time
from flask import stream_with_context

# T·∫°o Flask app
app = Flask(__name__)
CORS(app)

# Config
YOLO_MODEL_PATH = './models/best.pt'  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn model YOLO ƒë√£ train
model = "google/gemma-3-1b"  # Model LM Studio s·ª≠ d·ª•ng
client = OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio"  # Ch·ªâ l√† chu·ªói gi·∫£
)

# Session storage (trong production n√™n d√πng Redis)
chat_sessions = {}
session_lock = threading.Lock()

# Session cleanup thread
def cleanup_old_sessions():
    while True:
        with session_lock:
            current_time = datetime.now()
            expired_sessions = [
                session_id for session_id, session_data in chat_sessions.items()
                if current_time - session_data['last_activity'] > timedelta(hours=2)
            ]
            for session_id in expired_sessions:
                del chat_sessions[session_id]
        time.sleep(300)  # Check every 5 minutes

# Start cleanup thread
cleanup_thread = threading.Thread(target=cleanup_old_sessions, daemon=True)
cleanup_thread.start()

# Ingredient translation mapping
def datamap(ingredient):
    """
    Map English ingredient names to Vietnamese
    """
    translations = {
        "carrot": "C√† r·ªët",
        "chicken": "Th·ªãt g√†",
        "tomato": "C√† chua",
        "ginger": "G·ª´ng",
        "beans": "ƒê·∫≠u",
        "banana": "Chu·ªëi",
        "sponge_gourd": "M∆∞·ªõp h∆∞∆°ng",
        "onion": "H√†nh t√¢y",
        "garlic": "T·ªèi",
        "bell_pepper": "·ªöt chu√¥ng",
        "egg": "Tr·ª©ng",
        "avocado": "B∆°",
        "beet": "C·ªß d·ªÅn",
        "apple": "T√°o",
        "lemon": "Chanh v√†ng",
        "broccoli": "B√¥ng c·∫£i xanh",
        "bitter_gourd": "Kh·ªï qua",
        "chillies": "·ªöt",
        "fish": "C√°",
        "corn": "B·∫Øp",
        "okra": "ƒê·∫≠u b·∫Øp",
        "eggplant": "C√† t√≠m",
        "beef": "Th·ªãt b√≤",
        "cucumber": "D∆∞a leo",
        "potato": "Khoai t√¢y",
        "cabbage": "B·∫Øp c·∫£i",
        "cauliflower": "S√∫p l∆° tr·∫Øng",
        "cheese": "Ph√¥ mai",
        "shrimp": "T√¥m",
        "kimchi": "Kim chi",
        "lettuce": "X√† l√°ch",
        "mushroom": "N·∫•m",
        "sausage": "X√∫c x√≠ch",
        "coriander": "Rau m√πi",
        "pineapple": "Th∆°m",
        "lime": "Chanh xanh",
        "papaya": "ƒêu ƒë·ªß",
        "pork": "Th·ªãt heo",
        "dragon_fruit": "Thanh long",
        "pumpkin": "B√≠ ƒë·ªè",
        "pear": "L√™",
        "guava": "·ªîi",
        "calabash": "B·∫ßu",
        "watermelon": "D∆∞a h·∫•u",
        "turmeric": "Ngh·ªá"
    }
    
    return translations.get(ingredient, ingredient)  # Tr·∫£ v·ªÅ t√™n g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y

# Load YOLO model
print("üîÑ Loading YOLO model...")
try:
    yolo_model = YOLO(YOLO_MODEL_PATH)
    print(f"‚úÖ YOLO model loaded! Classes: {list(yolo_model.names.values())}")
    model_loaded = True
except Exception as e:
    print(f"‚ùå Failed to load YOLO model: {str(e)}")
    yolo_model = None
    model_loaded = False

# ==================== SESSION MANAGEMENT ====================

@app.route('/start-chat', methods=['POST'])
def start_chat():
    """T·∫°o session chat m·ªõi"""
    try:
        data = request.get_json() or {}
        ingredients = data.get('ingredients', [])
        recipe = data.get('recipe', '')
        
        session_id = str(uuid.uuid4())
        
        with session_lock:
            chat_sessions[session_id] = {
                'session_id': session_id,
                'ingredients': ingredients,
                'recipe': recipe,
                'messages': [],
                'created_at': datetime.now(),
                'last_activity': datetime.now()
            }
        
        print(f"‚úÖ Created chat session: {session_id}")
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'message': 'Chat session started successfully'
        })
        
    except Exception as e:
        print(f"‚ùå Start chat error: {str(e)}")
        return jsonify({
            'error': f'Failed to start chat: {str(e)}',
            'success': False
        }), 500

# ==================== YOLO DETECTION API ====================

@app.route('/detect', methods=['POST'])
def detect_ingredients():
    """
    API endpoint ƒë·ªÉ detect nguy√™n li·ªáu t·ª´ ·∫£nh
    """
    try:
        if not model_loaded:
            return jsonify({
                'error': 'YOLO model not loaded',
                'success': False,
                'ingredients': []
            }), 500
        
        # Ki·ªÉm tra c√≥ file trong request kh√¥ng
        if 'image' not in request.files:
            return jsonify({
                'error': 'No image file provided',
                'success': False,
                'ingredients': []
            }), 400
        
        file = request.files['image']
        
        # Ki·ªÉm tra file c√≥ ƒë∆∞·ª£c ch·ªçn kh√¥ng
        if file.filename == '':
            return jsonify({
                'error': 'No file selected',
                'success': False,
                'ingredients': []
            }), 400
        
        if file and allowed_file(file.filename):
            temp_file_path = None
            try:
                # L∆∞u t·∫°m th·ªùi v·ªõi proper error handling
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
                    file.save(temp_file.name)
                    temp_file_path = temp_file.name
                
                print(f"üñºÔ∏è Processing image: {temp_file_path}")
                
                # Ch·∫°y YOLO detection v·ªõi error handling
                results = yolo_model(temp_file_path, conf=0.3)
                print(f"üîç YOLO results: {len(results)} result(s)")
                
                # L·∫•y t√™n nguy√™n li·ªáu
                detailed_results = []
                
                for result in results:
                    print(f"üìä Processing result with {len(result.boxes) if result.boxes is not None else 0} boxes")
                    
                    if result.boxes is not None and len(result.boxes) > 0:
                        for i, box in enumerate(result.boxes):
                            try:
                                # Safely extract values
                                class_id = int(box.cls[0].item()) 
                                confidence = float(box.conf[0].item())
                                
                                # Check if class_id exists in model names
                                if class_id in yolo_model.names:
                                    class_name = yolo_model.names[class_id]
                                    
                                    detailed_results.append({
                                        'name': class_name,
                                        'confidence': confidence,
                                        'class_id': class_id
                                    })
                                    
                                    print(f"  ‚úÖ Box {i}: {class_name} (confidence: {confidence:.3f})")
                                else:
                                    print(f"  ‚ö†Ô∏è Box {i}: Unknown class_id {class_id}")
                                    
                            except Exception as box_error:
                                print(f"  ‚ùå Error processing box {i}: {str(box_error)}")
                                continue
                
                print(f"üìã Total detections: {len(detailed_results)}")
                
                # Ch·ªâ tr·∫£ v·ªÅ t√™n, kh√¥ng tr√πng, s·∫Øp x·∫øp theo confidence
                unique_ingredients = {}
                for item in detailed_results:
                    name = item['name']
                    if name not in unique_ingredients or item['confidence'] > unique_ingredients[name]['confidence']:
                        unique_ingredients[name] = item
                
                # Sort theo confidence gi·∫£m d·∫ßn
                sorted_results = sorted(unique_ingredients.values(), key=lambda x: x['confidence'], reverse=True)
                
                # Translate ingredients to Vietnamese
                final_ingredients = []
                translated_results = []
                
                for item in sorted_results:
                    english_name = item['name']
                    vietnamese_name = datamap(english_name)
                    
                    final_ingredients.append(vietnamese_name)
                    translated_results.append({
                        'name': vietnamese_name,
                        'english_name': english_name,
                        'confidence': item['confidence'],
                        'class_id': item['class_id']
                    })
                
                print(f"üéØ Final ingredients (EN): {[item['name'] for item in sorted_results]}")
                print(f"üéØ Final ingredients (VI): {final_ingredients}")
                
                return jsonify({
                    'success': True,
                    'ingredients': final_ingredients,
                    'detailed_results': translated_results,
                    'total_detected': len(final_ingredients)
                })
                
            except Exception as detection_error:
                print(f"‚ùå Detection error: {str(detection_error)}")
                print(f"üìç Error traceback: {traceback.format_exc()}")
                
                return jsonify({
                    'error': f'Detection failed: {str(detection_error)}',
                    'success': False,
                    'ingredients': []
                }), 500
            
            finally:
                # Cleanup temp file
                if temp_file_path and os.path.exists(temp_file_path):
                    try:
                        os.unlink(temp_file_path)
                        print(f"üóëÔ∏è Cleaned up temp file: {temp_file_path}")
                    except Exception as cleanup_error:
                        print(f"‚ö†Ô∏è Failed to cleanup temp file: {str(cleanup_error)}")
        
        return jsonify({
            'error': 'Invalid file type. Supported: png, jpg, jpeg, gif, bmp, webp',
            'success': False,
            'ingredients': []
        }), 400
        
    except Exception as e:
        print(f"‚ùå Main error in detect_ingredients: {str(e)}")
        print(f"üìç Error traceback: {traceback.format_exc()}")
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False,
            'ingredients': []
        }), 500

def allowed_file(filename):
    """Ki·ªÉm tra file c√≥ h·ª£p l·ªá kh√¥ng"""
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/classes', methods=['GET'])
def get_classes():
    """
    API ƒë·ªÉ l·∫•y danh s√°ch c√°c class m√† model c√≥ th·ªÉ detect
    """
    if not model_loaded:
        return jsonify({
            'error': 'YOLO model not loaded',
            'success': False
        }), 500
    
    # Get English classes and translate to Vietnamese
    english_classes = list(yolo_model.names.values())
    vietnamese_classes = [datamap(cls) for cls in english_classes]
    
    # Create mapping for reference
    class_mapping = {}
    for i, english_name in enumerate(english_classes):
        vietnamese_name = datamap(english_name)
        class_mapping[i] = {
            'english': english_name,
            'vietnamese': vietnamese_name
        }
    
    return jsonify({
        'success': True,
        'classes': vietnamese_classes,
        'english_classes': english_classes,
        'class_mapping': class_mapping,
        'total_classes': len(english_classes)
    })

# ==================== LM STUDIO RECIPE API ====================

@app.route('/generate-recipe', methods=['POST'])
def generate_recipe():
    """
    API endpoint ƒë·ªÉ t·∫°o c√¥ng th·ª©c t·ª´ nguy√™n li·ªáu
    """
    try:
        data = request.get_json()
        
        if not data or 'ingredients' not in data:
            return jsonify({
                'error': 'No ingredients provided',
                'success': False
            }), 400
        
        ingredients = data['ingredients']
        
        if not ingredients:
            return jsonify({
                'error': 'Ingredients list is empty',
                'success': False
            }), 400
        
        # T·∫°o prompt cho LM Studio
        ingredients_text = ', '.join(ingredients)
        prompt = f"""
B·∫°n l√† m·ªôt ƒë·∫ßu b·∫øp Vi·ªát Nam chuy√™n nghi·ªáp. B·∫°n ch·ªâ ƒë∆∞·ª£c ph√©p tr·∫£ l·ªùi v·ªÅ c√°c m√≥n ƒÉn Vi·ªát Nam, ƒë·∫∑c bi·ªát l√† ƒë∆∞a ra g·ª£i √Ω m√≥n ƒÉn d·ª±a tr√™n nguy√™n li·ªáu c√≥ s·∫µn.
T·ª´ c√°c nguy√™n li·ªáu: {ingredients_text}

H√£y g·ª£i √Ω 3 m√≥n ƒÉn Vi·ªát Nam ph√π h·ª£p v·ªõi c√¥ng th·ª©c chi ti·∫øt bao g·ªìm:

üç≤ [T√™n m√≥n ƒÉn]

Nguy√™n li·ªáu ch√≠nh: {ingredients_text}

Nguy√™n li·ªáu th√™m:
- [Li·ªát k√™ nguy√™n li·ªáu c·∫ßn th√™m]

C√°ch l√†m:
1. S∆° ch·∫ø: [H∆∞·ªõng d·∫´n s∆° ch·∫ø]
2. N·∫•u: [C√°c b∆∞·ªõc n·∫•u chi ti·∫øt]
3. N√™m n·∫øm: [C√°ch n√™m n·∫øm]
4. Ho√†n th√†nh: [B∆∞·ªõc cu·ªëi c√πng]

‚è±Ô∏è Th·ªùi gian: [X ph√∫t] | üåü ƒê·ªô kh√≥: [D·ªÖ/Trung b√¨nh/Kh√≥]

L∆∞u √Ω: H∆∞·ªõng d·∫´n ph·∫£i r√µ r√†ng, d·ªÖ hi·ªÉu, ph√π h·ª£p v·ªõi ng∆∞·ªùi Vi·ªát.
Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng text th∆∞·ªùng, kh√¥ng th√™m c√°c tag HTML hay Markdown ho·∫∑c c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh√°c.
Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ m√≥n ƒÉn n√†y, h√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† cung c·∫•p c√¥ng th·ª©c chi ti·∫øt.
N·∫øu h·ªèi c√°c c√¢u h·ªèi ngo√†i lƒ©nh v·ª±c n√†y, h√£y tr·∫£ l·ªùi r·∫±ng b·∫°n ch·ªâ chuy√™n v·ªÅ m√≥n ƒÉn Vi·ªát Nam v√† kh√¥ng th·ªÉ cung c·∫•p th√¥ng tin kh√°c.
"""
        try:
            print("ü§ñ Calling LM Studio API...")
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "B·∫°n l√† ƒë·∫ßu b·∫øp chuy√™n nghi·ªáp, chuy√™n m√≥n ƒÉn Vi·ªát Nam. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
            )
            
            recipe = response.choices[0].message.content
            print("‚úÖ Recipe generated successfully")
            
            return jsonify({
                'success': True,
                'recipe': recipe,
                'ingredients_used': ingredients
            })
            
        except Exception as api_error:
            print(f"‚ùå LM Studio API error: {str(api_error)}")
            return jsonify({
                'error': f'Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi LM Studio API. Vui l√≤ng ki·ªÉm tra: {str(api_error)}',
                'success': False,
                'troubleshooting': [
                    'Ki·ªÉm tra LM Studio c√≥ ƒëang ch·∫°y kh√¥ng (localhost:1234)',
                    'Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c load ch∆∞a',
                    'Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng',
                    'Xem l·∫°i c·∫•u h√¨nh API endpoint'
                ]
            }), 503
            
    except Exception as e:
        print(f"‚ùå Generate recipe error: {str(e)}")
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False
        }), 500

# ==================== CHAT API WITH CONTEXT & STREAMING ====================

@app.route('/chat-stream', methods=['POST'])
def chat_stream():
    """Chat v·ªõi streaming response v√† context memory"""
    data = request.get_json()
    session_id = data.get('session_id')
    question = data.get('question', '')

    @stream_with_context
    def generate_response():
        try:
            if not session_id or not question:
                yield f"data: {json.dumps({'error': 'Missing session_id or question', 'type': 'error'})}\n\n"
                return
            # Get session
            with session_lock:
                if session_id not in chat_sessions:
                    yield f"data: {json.dumps({'error': 'Session not found or expired', 'type': 'error'})}\n\n"
                    return
                session = chat_sessions[session_id]
                session['last_activity'] = datetime.now()
            # Build context from previous messages
            ingredients_text = ', '.join(session['ingredients']) if session['ingredients'] else "c√°c nguy√™n li·ªáu c√≥ s·∫µn"
            recipe_context = session['recipe'][:400] if session['recipe'] else ""
            system_prompt = f"""
                B·∫°n l√† m·ªôt chuy√™n gia ·∫©m th·ª±c Vi·ªát Nam chuy√™n nghi·ªáp. 
                B·∫°n ch·ªâ c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn n·∫•u ƒÉn, nguy√™n li·ªáu, m√≥n ƒÉn, c√¥ng th·ª©c ho·∫∑c m·∫πo v·∫∑t nh√† b·∫øp.

                Nguy√™n li·ªáu hi·ªán c√≥: {ingredients_text}
                C√¥ng th·ª©c ƒëang th·∫£o lu·∫≠n: {recipe_context}

                QUY T·∫ÆC B·∫ÆT BU·ªòC:
                - B·∫°n TUY·ªÜT ƒê·ªêI KH√îNG ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫•t k·ª≥ n·ªôi dung n√†o ngo√†i n·∫•u ƒÉn, k·ªÉ c·∫£ khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ l·∫≠p tr√¨nh, khoa h·ªçc, game, hay b·∫•t k·ª≥ lƒ©nh v·ª±c n√†o kh√°c. B·∫°n ch·ªâ ƒë∆∞·ª£c ph√©p n√≥i ƒë√∫ng c√¢u: "Xin l·ªói t√¥i ch·ªâ c√≥ th·ªÉ tr·∫£ l·ªùi v·ªÅ n·∫•u ƒÉn. N·∫øu b·∫°n c√≥ c√¢u h·ªèi n√†o kh√°c, h√£y cho t√¥i bi·∫øt."
                - KH√îNG ƒë∆∞·ª£c suy lu·∫≠n ho·∫∑c tr·∫£ l·ªùi b·∫•t k·ª≥ th√¥ng tin n√†o ngo√†i lƒ©nh v·ª±c ·∫©m th·ª±c.
                - Tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, ƒë√∫ng tr·ªçng t√¢m, b·∫±ng ti·∫øng Vi·ªát.
                - KH√îNG d√πng HTML, Markdown, ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát.
                - Tr·∫£ l·ªùi theo d·∫°ng vƒÉn b·∫£n th∆∞·ªùng, kh√¥ng c√≥ ƒë·ªãnh d·∫°ng ph·ª©c t·∫°p, xu·ªëng d√≤ng h·ª£p l√Ω.
                - Duy tr√¨ gi·ªçng ƒëi·ªáu l·ªãch s·ª±, chuy√™n nghi·ªáp nh∆∞ng g·∫ßn g≈©i.

                L∆ØU √ù: Lu√¥n b√°m s√°t nguy√™n li·ªáu v√† c√¥ng th·ª©c ƒëang th·∫£o lu·∫≠n n·∫øu c√≥.
                """
            context_messages = [{"role": "system", "content": system_prompt}]
            # Add previous conversation history (last 8 messages)
            for msg in session['messages'][-8:]:
                context_messages.append({"role": "user", "content": msg['question']})
                context_messages.append({"role": "assistant", "content": msg['answer']})
            # Add current question
            context_messages.append({"role": "user", "content": question})
            print(f"ü§ñ Streaming chat - Session: {session_id}, Question: {question[:50]}...")
            # Stream response t·ª´ LM Studio
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=context_messages,
                    stream=True,
                    temperature=0.7,
                    max_tokens=500
                )
                full_answer = ""
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_answer += content
                        yield f"data: {json.dumps({'content': content, 'type': 'chunk'})}\n\n"
                # Save complete answer to session
                with session_lock:
                    if session_id in chat_sessions:
                        chat_sessions[session_id]['messages'].append({
                            'question': question,
                            'answer': full_answer.strip(),
                            'timestamp': datetime.now().isoformat()
                        })
                        chat_sessions[session_id]['last_activity'] = datetime.now()
                yield f"data: {json.dumps({'type': 'done', 'full_answer': full_answer.strip()})}\n\n"
                print("‚úÖ Streaming response completed")
            except Exception as api_error:
                print(f"‚ùå LM Studio API error: {str(api_error)}")
                # Fallback response based on question keywords
                question_lower = question.lower()
                fallback_answer = ""
                if 'th·ªùi gian' in question_lower or 'bao l√¢u' in question_lower:
                    fallback_answer = 'Th·ªùi gian chu·∫©n b·ªã kho·∫£ng 10 ph√∫t, n·∫•u 15-20 ph√∫t. T·ªïng c·ªông kho·∫£ng 25-30 ph√∫t l√† xong nh√©!'
                elif 'l·ª≠a' in question_lower or 'nhi·ªát ƒë·ªô' in question_lower:
                    fallback_answer = 'N√™n d√πng l·ª≠a v·ª´a khi x√†o th·ªãt, l·ª≠a to khi ƒëun s√¥i n∆∞·ªõc. L∆∞u √Ω ƒë·∫£o ƒë·ªÅu tay ƒë·ªÉ kh√¥ng b·ªã ch√°y!'
                elif 'ng∆∞·ªùi' in question_lower or 'kh·∫©u ph·∫ßn' in question_lower:
                    fallback_answer = 'C√¥ng th·ª©c n√†y ƒë·ªß cho 3-4 ng∆∞·ªùi ƒÉn. N·∫øu mu·ªën nhi·ªÅu h∆°n th√¨ nh√¢n ƒë√¥i nguy√™n li·ªáu nh√©!'
                elif 'm·∫πo' in question_lower or 'ngon' in question_lower:
                    fallback_answer = 'M·∫πo: ∆∞·ªõp th·ªãt k·ªπ tr∆∞·ªõc khi n·∫•u, rau c·ªß kh√¥ng n√™n x√†o qu√° l√¢u ƒë·ªÉ gi·ªØ ƒë·ªô gi√≤n. N√™m n·∫øm t·ª´ t·ª´ cho v·ª´a mi·ªáng!'
                elif 'dai' in question_lower and 'th·ªãt' in question_lower:
                    fallback_answer = 'ƒê·ªÉ th·ªãt kh√¥ng dai: ∆∞·ªõp v·ªõi ch√∫t mu·ªëi v√† d·∫ßu ƒÉn 15 ph√∫t tr∆∞·ªõc khi n·∫•u, kh√¥ng n·∫•u qu√° l√¢u ·ªü nhi·ªát ƒë·ªô cao!'
                elif 'xanh' in question_lower and ('rau' in question_lower or 'c·∫£i' in question_lower):
                    fallback_answer = 'ƒê·ªÉ rau gi·ªØ m√†u xanh: cho rau v√†o khi n∆∞·ªõc ƒë√£ s√¥i, n·∫•u nhanh ·ªü l·ª≠a to, v·ªõt ra ngay khi ch√≠n t·ªõi!'
                else:
                    fallback_answer = 'D·ª±a tr√™n nguy√™n li·ªáu v√† c√¥ng th·ª©c hi·ªán t·∫°i, t√¥i khuy√™n b·∫°n n√™n ch√∫ √Ω ƒë·∫øn ƒë·ªô ch√≠n c·ªßa nguy√™n li·ªáu v√† n√™m n·∫øm ph√π h·ª£p. N·∫•u ƒÉn c·∫ßn ki√™n nh·∫´n v√† th·ª≠ n·∫øm ƒë·ªÉ c√≥ m√≥n ƒÉn ngon nh·∫•t!'
                # Stream fallback answer word by word
                words = fallback_answer.split(' ')
                full_fallback = ""
                for word in words:
                    full_fallback += word + " "
                    yield f"data: {json.dumps({'content': word + ' ', 'type': 'chunk'})}\n\n"
                    time.sleep(0.05)  # Small delay for streaming effect
                # Save fallback to session
                with session_lock:
                    if session_id in chat_sessions:
                        chat_sessions[session_id]['messages'].append({
                            'question': question,
                            'answer': fallback_answer,
                            'timestamp': datetime.now().isoformat()
                        })
                yield f"data: {json.dumps({'type': 'done', 'full_answer': fallback_answer, 'note': 'Fallback response'})}\n\n"
        except Exception as e:
            print(f"‚ùå Chat stream error: {str(e)}")
            yield f"data: {json.dumps({'error': str(e), 'type': 'error'})}\n\n"

    return Response(
        generate_response(),
        mimetype='text/plain',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type'
        }
    )

@app.route('/get-chat-history/<session_id>', methods=['GET'])
def get_chat_history(session_id):
    """L·∫•y l·ªãch s·ª≠ chat"""
    try:
        with session_lock:
            if session_id not in chat_sessions:
                return jsonify({
                    'error': 'Session not found',
                    'success': False
                }), 404
            
            session = chat_sessions[session_id]
            
        return jsonify({
            'success': True,
            'session_id': session_id,
            'ingredients': session['ingredients'],
            'recipe': session['recipe'],
            'messages': session['messages'],
            'created_at': session['created_at'].isoformat(),
            'last_activity': session['last_activity'].isoformat(),
            'total_messages': len(session['messages'])
        })
        
    except Exception as e:
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False
        }), 500

@app.route('/end-chat/<session_id>', methods=['DELETE'])
def end_chat(session_id):
    """K·∫øt th√∫c session chat"""
    try:
        with session_lock:
            if session_id in chat_sessions:
                del chat_sessions[session_id]
                print(f"üóëÔ∏è Ended chat session: {session_id}")
                return jsonify({
                    'success': True,
                    'message': 'Chat session ended'
                })
            else:
                return jsonify({
                    'error': 'Session not found',
                    'success': False
                }), 404
                
    except Exception as e:
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False
        }), 500

# ==================== HEALTH & INFO ENDPOINTS ====================

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint with session info"""
    try:
        # Test LM Studio connection
        lm_studio_status = "unknown"
        try:
            test_response = client.chat.completions.create(
                model="google/gemma-3-1b",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1,
                timeout=5
            )
            lm_studio_status = "connected"
        except Exception as e:
            lm_studio_status = f"disconnected: {str(e)}"
        
        # Session statistics
        with session_lock:
            active_sessions = len(chat_sessions)
            session_stats = {
                'active_sessions': active_sessions,
                'sessions': [
                    {
                        'session_id': sid,
                        'messages_count': len(data['messages']),
                        'last_activity': data['last_activity'].isoformat(),
                        'ingredients_count': len(data['ingredients'])
                    }
                    for sid, data in chat_sessions.items()
                ]
            }
        
        return jsonify({
            'status': 'healthy',
            'yolo_model_loaded': model_loaded,
            'lm_studio_status': lm_studio_status,
            'lm_studio_url': 'http://localhost:1234/v1',
            'session_stats': session_stats,
            'endpoints': [
                'POST /detect - YOLO detection',
                'GET /classes - Get YOLO classes',
                'POST /generate-recipe - Generate recipe',
                'POST /start-chat - Start chat session',
                'POST /chat-stream - Chat with streaming & context',
                'GET /get-chat-history/<id> - Get chat history',
                'DELETE /end-chat/<id> - End chat session',
                'GET /health - Health check'
            ]
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/', methods=['GET'])
def root():
    """Root endpoint v·ªõi th√¥ng tin API"""
    info = {
        'name': 'Food Detection & Recipe API with Context Chat',
        'version': '2.0.0',
        'status': 'running',
        'yolo_model': 'loaded' if model_loaded else 'failed',
        'features': [
            'YOLO ingredient detection',
            'LM Studio recipe generation',
            'Context-aware streaming chat',
            'Session management',
            'Chat history'
        ],
        'endpoints': {
            'detection': {
                'POST /detect': 'Upload ·∫£nh ƒë·ªÉ detect nguy√™n li·ªáu',
                'GET /classes': 'L·∫•y danh s√°ch classes YOLO c√≥ th·ªÉ detect'
            },
            'recipe': {
                'POST /generate-recipe': 'T·∫°o c√¥ng th·ª©c t·ª´ nguy√™n li·ªáu'
            },
            'chat': {
                'POST /start-chat': 'B·∫Øt ƒë·∫ßu session chat v·ªõi context',
                'POST /chat-stream': 'Chat v·ªõi streaming response',
                'GET /get-chat-history/<id>': 'L·∫•y l·ªãch s·ª≠ chat',
                'DELETE /end-chat/<id>': 'K·∫øt th√∫c session chat'
            },
            'info': {
                'GET /health': 'Health check',
                'GET /': 'API information'
            }
        },
        'usage': {
            'detection': 'curl -X POST -F "image=@photo.jpg" http://localhost:5000/detect',
            'recipe': 'curl -X POST -H "Content-Type: application/json" -d \'{"ingredients":["th·ªãt b√≤","c√† r·ªët"]}\' http://localhost:5000/generate-recipe',
            'chat': 'curl -X POST -H "Content-Type: application/json" -d \'{"ingredients":["th·ªãt b√≤"],"recipe":"..."}\' http://localhost:5000/start-chat'
        }
    }
    
    return jsonify(info)

if __name__ == '__main__':
    print("üöÄ Food Detection & Recipe API with Context Chat Starting...")
    print("=" * 60)
    print(f"üìÅ YOLO Model: {'‚úÖ Loaded' if model_loaded else '‚ùå Failed'}")
    if model_loaded:
        print(f"üè∑Ô∏è  Detected Classes: {list(yolo_model.names.values())}")
    print(f"ü§ñ LM Studio URL: http://localhost:1234/v1")
    print("üåê Server URL: http://localhost:5000")
    print("=" * 60)
    print("üìã Available Endpoints:")
    print("  POST /detect                    - YOLO ingredient detection")
    print("  GET  /classes                   - Get available classes")
    print("  POST /generate-recipe           - Generate recipe from ingredients")
    print("  POST /start-chat                - Start chat session with context")
    print("  POST /chat-stream               - Chat with streaming response")
    print("  GET  /get-chat-history/<id>     - Get chat history")
    print("  DELETE /end-chat/<id>           - End chat session")
    print("  GET  /health                    - Health check")
    print("  GET  /                          - API info")
    print("=" * 60)
    print("üÜï New Features:")
    print("  ‚úÖ Session-based context memory")
    print("  ‚úÖ Real-time streaming responses")
    print("  ‚úÖ Chat history storage")
    print("  ‚úÖ Automatic session cleanup")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=5000, debug=True)