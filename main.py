from flask import Flask, request, jsonify
from flask_cors import CORS
from ultralytics import YOLO
import tempfile
import os
import json
import traceback
from openai import OpenAI

# T·∫°o Flask app
app = Flask(__name__)
CORS(app)

# Config
YOLO_MODEL_PATH = './models/best.pt'  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn model YOLO ƒë√£ train
client = OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio"  # Ch·ªâ l√† chu·ªói gi·∫£
)

# Load YOLO model
print("üîÑ Loading YOLO model...")
try:
    yolo_model = YOLO(YOLO_MODEL_PATH)
    print(f"‚úÖ YOLO model loaded! Classes: {list(yolo_model.names.values())}")
    model_loaded = True
except Exception as e:
    print(f"‚ùå Failed to load YOLO model: {str(e)}")
    yolo_model = None
    model_loaded = False

# ==================== YOLO DETECTION API ====================

@app.route('/detect', methods=['POST'])
def detect_ingredients():
    """
    API endpoint ƒë·ªÉ detect nguy√™n li·ªáu t·ª´ ·∫£nh
    """
    try:
        if not model_loaded:
            return jsonify({
                'error': 'YOLO model not loaded',
                'success': False,
                'ingredients': []
            }), 500
        
        # Ki·ªÉm tra c√≥ file trong request kh√¥ng
        if 'image' not in request.files:
            return jsonify({
                'error': 'No image file provided',
                'success': False,
                'ingredients': []
            }), 400
        
        file = request.files['image']
        
        # Ki·ªÉm tra file c√≥ ƒë∆∞·ª£c ch·ªçn kh√¥ng
        if file.filename == '':
            return jsonify({
                'error': 'No file selected',
                'success': False,
                'ingredients': []
            }), 400
        
        if file and allowed_file(file.filename):
            temp_file_path = None
            try:
                # L∆∞u t·∫°m th·ªùi v·ªõi proper error handling
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
                    file.save(temp_file.name)
                    temp_file_path = temp_file.name
                
                print(f"üñºÔ∏è Processing image: {temp_file_path}")
                
                # Ch·∫°y YOLO detection v·ªõi error handling
                results = yolo_model(temp_file_path, conf=0.3)
                print(f"üîç YOLO results: {len(results)} result(s)")
                
                # L·∫•y t√™n nguy√™n li·ªáu
                detailed_results = []
                
                for result in results:
                    print(f"üìä Processing result with {len(result.boxes) if result.boxes is not None else 0} boxes")
                    
                    if result.boxes is not None and len(result.boxes) > 0:
                        for i, box in enumerate(result.boxes):
                            try:
                                # Safely extract values
                                class_id = int(box.cls[0].item()) 
                                confidence = float(box.conf[0].item())
                                
                                # Check if class_id exists in model names
                                if class_id in yolo_model.names:
                                    class_name = yolo_model.names[class_id]
                                    
                                    detailed_results.append({
                                        'name': class_name,
                                        'confidence': confidence,
                                        'class_id': class_id
                                    })
                                    
                                    print(f"  ‚úÖ Box {i}: {class_name} (confidence: {confidence:.3f})")
                                else:
                                    print(f"  ‚ö†Ô∏è Box {i}: Unknown class_id {class_id}")
                                    
                            except Exception as box_error:
                                print(f"  ‚ùå Error processing box {i}: {str(box_error)}")
                                continue
                
                print(f"üìã Total detections: {len(detailed_results)}")
                
                # Ch·ªâ tr·∫£ v·ªÅ t√™n, kh√¥ng tr√πng, s·∫Øp x·∫øp theo confidence
                unique_ingredients = {}
                for item in detailed_results:
                    name = item['name']
                    if name not in unique_ingredients or item['confidence'] > unique_ingredients[name]['confidence']:
                        unique_ingredients[name] = item
                
                # Sort theo confidence gi·∫£m d·∫ßn
                sorted_results = sorted(unique_ingredients.values(), key=lambda x: x['confidence'], reverse=True)
                final_ingredients = [item['name'] for item in sorted_results]
                
                print(f"üéØ Final ingredients: {final_ingredients}")
                
                return jsonify({
                    'success': True,
                    'ingredients': final_ingredients,
                    'detailed_results': sorted_results,
                    'total_detected': len(final_ingredients)
                })
                
            except Exception as detection_error:
                print(f"‚ùå Detection error: {str(detection_error)}")
                print(f"üìç Error traceback: {traceback.format_exc()}")
                
                return jsonify({
                    'error': f'Detection failed: {str(detection_error)}',
                    'success': False,
                    'ingredients': []
                }), 500
            
            finally:
                # Cleanup temp file
                if temp_file_path and os.path.exists(temp_file_path):
                    try:
                        os.unlink(temp_file_path)
                        print(f"üóëÔ∏è Cleaned up temp file: {temp_file_path}")
                    except Exception as cleanup_error:
                        print(f"‚ö†Ô∏è Failed to cleanup temp file: {str(cleanup_error)}")
        
        return jsonify({
            'error': 'Invalid file type. Supported: png, jpg, jpeg, gif, bmp, webp',
            'success': False,
            'ingredients': []
        }), 400
        
    except Exception as e:
        print(f"‚ùå Main error in detect_ingredients: {str(e)}")
        print(f"üìç Error traceback: {traceback.format_exc()}")
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False,
            'ingredients': []
        }), 500

def allowed_file(filename):
    """Ki·ªÉm tra file c√≥ h·ª£p l·ªá kh√¥ng"""
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/classes', methods=['GET'])
def get_classes():
    """
    API ƒë·ªÉ l·∫•y danh s√°ch c√°c class m√† model c√≥ th·ªÉ detect
    """
    if not model_loaded:
        return jsonify({
            'error': 'YOLO model not loaded',
            'success': False
        }), 500
    
    return jsonify({
        'success': True,
        'classes': list(yolo_model.names.values()),
        'total_classes': len(yolo_model.names)
    })

# ==================== LM STUDIO RECIPE API ====================

@app.route('/generate-recipe', methods=['POST'])
def generate_recipe():
    """
    API endpoint ƒë·ªÉ t·∫°o c√¥ng th·ª©c t·ª´ nguy√™n li·ªáu
    """
    try:
        data = request.get_json()
        
        if not data or 'ingredients' not in data:
            return jsonify({
                'error': 'No ingredients provided',
                'success': False
            }), 400
        
        ingredients = data['ingredients']
        
        if not ingredients:
            return jsonify({
                'error': 'Ingredients list is empty',
                'success': False
            }), 400
        
        # T·∫°o prompt cho LM Studio
        ingredients_text = ', '.join(ingredients)
        prompt = f"""T·ª´ c√°c nguy√™n li·ªáu: {ingredients_text}

H√£y g·ª£i √Ω 3 m√≥n ƒÉn Vi·ªát Nam ph√π h·ª£p v·ªõi c√¥ng th·ª©c chi ti·∫øt bao g·ªìm:

üç≤ [T√™n m√≥n ƒÉn]

Nguy√™n li·ªáu ch√≠nh: {ingredients_text}

Nguy√™n li·ªáu th√™m:
- [Li·ªát k√™ nguy√™n li·ªáu c·∫ßn th√™m]

C√°ch l√†m:
1. S∆° ch·∫ø: [H∆∞·ªõng d·∫´n s∆° ch·∫ø]
2. N·∫•u: [C√°c b∆∞·ªõc n·∫•u chi ti·∫øt]
3. N√™m n·∫øm: [C√°ch n√™m n·∫øm]
4. Ho√†n th√†nh: [B∆∞·ªõc cu·ªëi c√πng]

‚è±Ô∏è Th·ªùi gian: [X ph√∫t] | üåü ƒê·ªô kh√≥: [D·ªÖ/Trung b√¨nh/Kh√≥]

L∆∞u √Ω: H∆∞·ªõng d·∫´n ph·∫£i r√µ r√†ng, d·ªÖ hi·ªÉu, ph√π h·ª£p v·ªõi ng∆∞·ªùi Vi·ªát.
Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ m√≥n ƒÉn n√†y, h√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† cung c·∫•p c√¥ng th·ª©c chi ti·∫øt.
N·∫øu h·ªèi c√°c c√¢u h·ªèi ngo√†i lƒ©nh v·ª±c n√†y, h√£y tr·∫£ l·ªùi r·∫±ng b·∫°n ch·ªâ chuy√™n v·ªÅ m√≥n ƒÉn Vi·ªát Nam v√† kh√¥ng th·ªÉ cung c·∫•p th√¥ng tin kh√°c."""

        try:
            print("ü§ñ Calling LM Studio API...")
            response = client.chat.completions.create(
                model="google/gemma-3-1b",  # ho·∫∑c t√™n model b·∫°n ƒë√£ c·∫•u h√¨nh cho LM Studio
                messages=[
                    {"role": "system", "content": "B·∫°n l√† ƒë·∫ßu b·∫øp chuy√™n nghi·ªáp, chuy√™n m√≥n ƒÉn Vi·ªát Nam. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            recipe = response.choices[0].message.content
            print("‚úÖ Recipe generated successfully")
            
            return jsonify({
                'success': True,
                'recipe': recipe,
                'ingredients_used': ingredients
            })
            
        except Exception as api_error:
            print(f"‚ùå LM Studio API error: {str(api_error)}")
            return jsonify({
                'error': f'Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi LM Studio API. Vui l√≤ng ki·ªÉm tra: {str(api_error)}',
                'success': False,
                'troubleshooting': [
                    'Ki·ªÉm tra LM Studio c√≥ ƒëang ch·∫°y kh√¥ng (localhost:1234)',
                    'Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c load ch∆∞a',
                    'Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng',
                    'Xem l·∫°i c·∫•u h√¨nh API endpoint'
                ]
            }), 503
            
    except Exception as e:
        print(f"‚ùå Generate recipe error: {str(e)}")
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False
        }), 500

# ==================== SMART QUESTIONS API ====================

@app.route('/generate-questions', methods=['POST'])
def api_generate_questions():
    """API endpoint ƒë·ªÉ sinh c√¢u h·ªèi th√¥ng minh"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'error': 'No data provided',
                'success': False
            }), 400
        
        ingredients = data.get('ingredients', [])
        recipe = data.get('recipe', None)
        
        if not ingredients:
            return jsonify({
                'error': 'No ingredients provided',
                'success': False
            }), 400
        
        ingredients_text = ', '.join(ingredients)
        
        prompt = f"""D·ª±a tr√™n nguy√™n li·ªáu: {ingredients_text}
{"V√† c√¥ng th·ª©c: " + recipe[:200] + "..." if recipe else ""}

H√£y t·∫°o 4 c√¢u h·ªèi ph·ªï bi·∫øn m√† ng∆∞·ªùi d√πng Vi·ªát Nam th∆∞·ªùng h·ªèi v·ªÅ m√≥n ƒÉn n√†y.

Tr·∫£ v·ªÅ format JSON h·ª£p l·ªá nh∆∞ sau:
[
  {{"text": "C√¢u h·ªèi ng·∫Øn hi·ªÉn th·ªã", "question": "C√¢u h·ªèi ƒë·∫ßy ƒë·ªß g·ª≠i cho bot", "category": "time"}},
  {{"text": "C√¢u h·ªèi ng·∫Øn hi·ªÉn th·ªã", "question": "C√¢u h·ªèi ƒë·∫ßy ƒë·ªß g·ª≠i cho bot", "category": "technique"}},
  {{"text": "C√¢u h·ªèi ng·∫Øn hi·ªÉn th·ªã", "question": "C√¢u h·ªèi ƒë·∫ßy ƒë·ªß g·ª≠i cho bot", "category": "portion"}},
  {{"text": "C√¢u h·ªèi ng·∫Øn hi·ªÉn th·ªã", "question": "C√¢u h·ªèi ƒë·∫ßy ƒë·ªß g·ª≠i cho bot", "category": "tips"}}
]

Categories ch·ªâ ƒë∆∞·ª£c ph√©p: time, technique, portion, tips"""

        try:
            print("ü§ñ Generating smart questions...")
            response = client.chat.completions.create(
                model="google/gemma-3-1b",
                messages=[
                    {"role": "system", "content": "B·∫°n l√† chuy√™n gia ·∫©m th·ª±c. Ch·ªâ tr·∫£ l·ªùi b·∫±ng JSON h·ª£p l·ªá, kh√¥ng th√™m text n√†o kh√°c."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=600
            )
            
            content = response.choices[0].message.content.strip()
            print(f"üìù Raw response: {content}")
            
            # Parse JSON response
            questions = json.loads(content)
            
            # Validate structure
            if not isinstance(questions, list) or len(questions) != 4:
                raise ValueError("Invalid questions format")
            
            for q in questions:
                if not all(key in q for key in ['text', 'question', 'category']):
                    raise ValueError("Missing required fields in question")
            
            print("‚úÖ Questions generated successfully")
            
            return jsonify({
                'success': True,
                'questions': questions,
                'total': len(questions)
            })
            
        except json.JSONDecodeError as json_error:
            print(f"‚ùå JSON decode error: {str(json_error)}")
            return jsonify({
                'error': f'LM Studio tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá: {str(json_error)}',
                'success': False,
                'troubleshooting': [
                    'Model c√≥ th·ªÉ kh√¥ng hi·ªÉu y√™u c·∫ßu JSON',
                    'Th·ª≠ gi·∫£m max_tokens ho·∫∑c thay ƒë·ªïi prompt',
                    'Ki·ªÉm tra model c√≥ h·ªó tr·ª£ JSON output kh√¥ng'
                ]
            }), 422
            
        except Exception as api_error:
            print(f"‚ùå LM Studio API error: {str(api_error)}")
            return jsonify({
                'error': f'Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi LM Studio API: {str(api_error)}',
                'success': False,
                'troubleshooting': [
                    'Ki·ªÉm tra LM Studio c√≥ ƒëang ch·∫°y kh√¥ng (localhost:1234)',
                    'Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c load ch∆∞a',
                    'Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng'
                ]
            }), 503
        
    except Exception as e:
        print(f"‚ùå Generate questions error: {str(e)}")
        return jsonify({
            'error': f'Server error: {str(e)}',
            'success': False
        }), 500

# ==================== HEALTH & INFO ENDPOINTS ====================

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    # Test LM Studio connection
    lm_studio_status = "unknown"
    try:
        test_response = client.chat.completions.create(
            model="google/gemma-3-1b",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1,
            timeout=5
        )
        lm_studio_status = "connected"
    except Exception as e:
        lm_studio_status = f"disconnected: {str(e)}"
    
    return jsonify({
        'status': 'healthy',
        'yolo_model_loaded': model_loaded,
        'lm_studio_status': lm_studio_status,
        'lm_studio_url': 'http://localhost:1234/v1',
        'endpoints': [
            'POST /detect - YOLO detection',
            'GET /classes - Get YOLO classes',
            'POST /generate-recipe - Generate recipe',
            'POST /generate-questions - Generate smart questions',
            'GET /health - Health check'
        ]
    })

@app.route('/', methods=['GET'])
def root():
    """Root endpoint v·ªõi th√¥ng tin API"""
    info = {
        'name': 'Food Detection & Recipe API',
        'version': '1.0.0',
        'status': 'running',
        'yolo_model': 'loaded' if model_loaded else 'failed',
        'endpoints': {
            'detection': {
                'POST /detect': 'Upload ·∫£nh ƒë·ªÉ detect nguy√™n li·ªáu',
                'GET /classes': 'L·∫•y danh s√°ch classes YOLO c√≥ th·ªÉ detect'
            },
            'recipe': {
                'POST /generate-recipe': 'T·∫°o c√¥ng th·ª©c t·ª´ nguy√™n li·ªáu'
            },
            'questions': {
                'POST /generate-questions': 'T·∫°o c√¢u h·ªèi th√¥ng minh'
            },
            'info': {
                'GET /health': 'Health check',
                'GET /': 'API information'
            }
        },
        'usage': {
            'detection': 'curl -X POST -F "image=@photo.jpg" http://localhost:5000/detect',
            'recipe': 'curl -X POST -H "Content-Type: application/json" -d \'{"ingredients":["th·ªãt b√≤","c√† r·ªët"]}\' http://localhost:5000/generate-recipe'
        }
    }
    
    return jsonify(info)

if __name__ == '__main__':
    print("üöÄ Food Detection & Recipe API Server Starting...")
    print("=" * 50)
    print(f"üìÅ YOLO Model: {'‚úÖ Loaded' if model_loaded else '‚ùå Failed'}")
    if model_loaded:
        print(f"üè∑Ô∏è  Detected Classes: {list(yolo_model.names.values())}")
    print(f"ü§ñ LM Studio URL: http://localhost:1234/v1")
    print("üåê Server URL: http://localhost:5000")
    print("=" * 50)
    print("üìã Available Endpoints:")
    print("  POST /detect              - YOLO ingredient detection")
    print("  GET  /classes             - Get available classes")
    print("  POST /generate-recipe     - Generate recipe from ingredients")
    print("  POST /generate-questions  - Generate smart questions")
    print("  GET  /health              - Health check")
    print("  GET  /                    - API info")
    print("=" * 50)
    
    app.run(host='0.0.0.0', port=5000, debug=True)